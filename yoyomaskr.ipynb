{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yo-yo-maskr\n",
    "## Part 1: Regex based anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import regex as re\n",
    "from src.utils.ano_regex import create_names_regex\n",
    "from src.utils.trie import Trie\n",
    "\n",
    "NAMES_FROM_PICKLE = False\n",
    "USE_FULL = False\n",
    "\n",
    "if NAMES_FROM_PICKLE:\n",
    "    with open('./data/first_names_regex.pkl', 'rb') as f:\n",
    "        first_names = dill.load(f)\n",
    "    with open('./data/last_names_regex.pkl', 'rb') as f:\n",
    "        last_names = dill.load(f)\n",
    "    with open('./data/first_names_trie_regex.pkl', 'rb') as f:\n",
    "        first_names_trie = dill.load(f)\n",
    "    with open('./data/last_names_trie_regex.pkl', 'rb') as f:\n",
    "        last_names_trie = dill.load(f)\n",
    "else:\n",
    "    with open(f'./data/first_names{\"_full\" if USE_FULL else \"\"}.txt') as f:\n",
    "        first_names = [l.strip() for l in f.read().split('\\n') if len(l.strip()) > 0]\n",
    "    first_names_regex = create_names_regex(first_names)\n",
    "    with open('./data/first_names_regex.pkl', 'wb') as f:\n",
    "            dill.dump(first_names_regex, f)\n",
    "    first_trie = Trie()\n",
    "    for name in sorted([f for f in first_names if len(f) > 0], key=len, reverse=True):\n",
    "        first_trie.add(name)\n",
    "    first_trie_regex = re.compile(r'\\b' + first_trie.pattern() + r'\\b')\n",
    "    with open('./data/first_names_trie_regex.pkl', 'wb') as f:\n",
    "        dill.dump(first_trie_regex, f)\n",
    "\n",
    "    with open(f'./data/last_names{\"_full\" if USE_FULL else \"\"}.txt') as f:\n",
    "        last_names = [l.strip() for l in f.read().split('\\n') if len(l.strip()) > 0]\n",
    "    last_names_regex = create_names_regex(last_names)\n",
    "    with open('./data/last_names_regex.pkl', 'wb') as f:\n",
    "        dill.dump(last_names_regex, f)\n",
    "    last_trie = Trie()\n",
    "    for name in sorted([l for l in last_names if len(l) > 0], key=len, reverse=True):\n",
    "        last_trie.add(name)\n",
    "    last_trie_regex = re.compile(r'\\b' + last_trie.pattern() + r'\\b')\n",
    "    with open('./data/last_names_trie_regex.pkl', 'wb') as f:\n",
    "        dill.dump(last_trie_regex, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058ceb7dad11432496a6c565928e3083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import regex as re\n",
    "from tqdm.auto import tqdm\n",
    "from src.utils.ano_regex import anonymize_entities\n",
    "\n",
    "with open('./sample_texts.txt') as f:\n",
    "    sample_texts = [f.read()]\n",
    "    sample_texts = f.read().split('\\n')\n",
    "\n",
    "result = [anonymize_entities(text, by_names='NAME', first_names=first_trie_regex, last_names=last_trie_regex)\n",
    "          for text in tqdm(sample_texts[:])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0].get('replace_dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashtext2 import KeywordProcessor\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ln = KeywordProcessor(case_sensitive=True)\n",
    "for name in last_names:\n",
    "    ln.add_keyword(name)\n",
    "\n",
    "fn = KeywordProcessor(case_sensitive=True)\n",
    "for name in first_names:\n",
    "    fn.add_keyword(name)\n",
    "\n",
    "result = [{'text': text, 'first_names': fn.extract_keywords_with_span(text),\n",
    "           'last_names': ln.extract_keywords_with_span(text)} for text in tqdm(sample_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrie.trie import Trie\n",
    "\n",
    "retrie = Trie()\n",
    "for name in sorted([l for l in last_names if len(l) > 0], key=len, reverse=True):\n",
    "    retrie.add(name)\n",
    "\n",
    "retrie.pattern()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
